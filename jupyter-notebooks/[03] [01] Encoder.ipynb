{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_val(s, tfidf):\n",
    "#     values = list(tfidf.idf_)\n",
    "    feature_names = list(tfidf.get_feature_names_out())\n",
    "        \n",
    "    if s in feature_names:\n",
    "        index = feature_names.index(s)\n",
    "    else:\n",
    "        index = feature_names.index('unknown_tld')\n",
    "        \n",
    "    return tfidf.idf_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(token_pattern='.*')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Lendo o Dataset\n",
    "df = pd.read_csv('../Dataset/Train/Temp/pre_train.csv')\n",
    "\n",
    "# Seleção da coluna para transformar de texto para número\n",
    "train_texts = df['TLD']\n",
    "\n",
    "# Excluindo valores NaN\n",
    "train_texts.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# Adding 'UNKNOWN' to match new words\n",
    "train_texts = list(train_texts) + ['unknown_tld']\n",
    "\n",
    "# Inicializa tfidf\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\", token_pattern=\".*\")\n",
    "\n",
    "# treina tfidf\n",
    "vectorizer.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "# Saving the vectorizer\n",
    "dump(vectorizer, open('../Models/TF-IDF/vectorizer.pikle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Dataset/Train/Temp/pre_train.csv')\n",
    "train = train.fillna('')\n",
    "\n",
    "test = pd.read_csv('../Dataset/Test/Temp/pre_test.csv')\n",
    "test = test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TLD_TD_IDF'] = train['TLD'].apply(idf_val, tfidf=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "vectorizer = load(open('../Models/TF-IDF/vectorizer.pikle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TLD_TD_IDF'] = test['TLD'].apply(idf_val, tfidf=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLabelEncoder(LabelEncoder):\n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "\n",
    "def gen_encoder(lst):\n",
    "    lst = sorted(Counter(lst), key=Counter(lst).get, reverse=True)\n",
    "\n",
    "    unk_pos = len(lst)\n",
    "    # unk_pos = math.ceil(len(lst)/2)        \n",
    "    lst.insert(unk_pos, 'Unknown')\n",
    "    \n",
    "    label_encoder = MyLabelEncoder().fit(lst)    \n",
    "    return label_encoder\n",
    "\n",
    "def encode(item, encoder):\n",
    "    if item not in list(encoder.classes_):\n",
    "        item = 'Unknown'\n",
    "    lst = [item]\n",
    "    lst = encoder.transform(lst)\n",
    "    return lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating Encoders\n",
    "unq_tld = list(train['TLD'].unique())\n",
    "enc_tld = gen_encoder(unq_tld)\n",
    "\n",
    "allowed_chars = list(string.digits)+list(string.ascii_lowercase)+['-', '.', '']\n",
    "enc_chr = gen_encoder(allowed_chars)\n",
    "\n",
    "## Saving Encoders\n",
    "np.save('../Models/Encoders/enc_tld.npy', enc_tld.classes_)\n",
    "np.save('../Models/Encoders/enc_chr.npy', enc_chr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TLD'] = train['TLD'].apply(encode, encoder=enc_tld)\n",
    "\n",
    "train['SSD_val_3'] = train['SSD_val_3'].apply(encode, encoder=enc_chr)\n",
    "train['SUB_val_3'] = train['SUB_val_3'].apply(encode, encoder=enc_chr)\n",
    "train['SLD_val_3'] = train['SLD_val_3'].apply(encode, encoder=enc_chr)\n",
    "\n",
    "train['SSD_chr_seq_c'] = train['SSD_chr_seq_c'].apply(encode, encoder=enc_chr)\n",
    "train['SUB_chr_seq_c'] = train['SUB_chr_seq_c'].apply(encode, encoder=enc_chr)\n",
    "train['SLD_chr_seq_c'] = train['SLD_chr_seq_c'].apply(encode, encoder=enc_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../Dataset/Train/Temp/enc_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Encoders\n",
    "\n",
    "enc_tld = LabelEncoder()\n",
    "enc_tld.classes_ = np.load('../Models/Encoders/enc_tld.npy', allow_pickle=True)\n",
    "\n",
    "enc_chr = LabelEncoder()\n",
    "enc_chr.classes_ = np.load('../Models/Encoders/enc_chr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TLD'] = test['TLD'].apply(encode, encoder=enc_tld)\n",
    "\n",
    "test['SSD_val_3'] = test['SSD_val_3'].apply(encode, encoder=enc_chr)\n",
    "test['SUB_val_3'] = test['SUB_val_3'].apply(encode, encoder=enc_chr)\n",
    "test['SLD_val_3'] = test['SLD_val_3'].apply(encode, encoder=enc_chr)\n",
    "\n",
    "test['SSD_chr_seq_c'] = test['SSD_chr_seq_c'].apply(encode, encoder=enc_chr)\n",
    "test['SUB_chr_seq_c'] = test['SUB_chr_seq_c'].apply(encode, encoder=enc_chr)\n",
    "test['SLD_chr_seq_c'] = test['SLD_chr_seq_c'].apply(encode, encoder=enc_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../Dataset/Test/Temp/enc_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
